{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5whJ_nEyr-9m"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "# -------------------------------------------------\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import SimpleITK as sitk\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------------------------------\n",
        "# Config\n",
        "# -------------------------------------------------\n",
        "CT_SCANS_DIR = '/kaggle/input/luna-lung-cancer-dataset/seg-lungs-LUNA16/seg-lungs-LUNA16'\n",
        "ANNOTATIONS_CSV = '/kaggle/input/luna-lung-cancer-dataset/annotations.csv'\n",
        "CANDIDATES_CSV = '/kaggle/input/luna-lung-cancer-dataset/candidates.csv'\n",
        "PATCH_SIZE = 32\n",
        "BATCH_SIZE = 8\n",
        "NUM_EPOCHS = 50\n",
        "LEARNING_RATE = 1e-4\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "9yb2IUM5sLCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------------------------------\n",
        "# Utilities\n",
        "# -------------------------------------------------\n",
        "def load_itk(filename):\n",
        "    itkimage = sitk.ReadImage(filename)\n",
        "    img = sitk.GetArrayFromImage(itkimage)\n",
        "    origin = np.array(itkimage.GetOrigin())[::-1]\n",
        "    spacing = np.array(itkimage.GetSpacing())[::-1]\n",
        "    return img, origin, spacing\n",
        "\n",
        "def world_to_voxel(world_coord, origin, spacing):\n",
        "    stretched = np.abs(world_coord - origin)\n",
        "    voxel_coord = stretched / spacing\n",
        "    return voxel_coord\n",
        "\n",
        "def extract_patch(img, center, size):\n",
        "    center = [int(c) for c in center]\n",
        "    size = [int(s) for s in (size, size, size)]\n",
        "    start = [max(c - s//2, 0) for c, s in zip(center, size)]\n",
        "    end = [start[i] + size[i] for i in range(3)]\n",
        "    slices = tuple(slice(start[i], end[i]) for i in range(3))\n",
        "    patch = img[slices]\n",
        "    if patch.shape != (size[0], size[1], size[2]):\n",
        "        pad_width = [(0, max(0, size[i] - patch.shape[i])) for i in range(3)]\n",
        "        patch = np.pad(patch, pad_width, mode='constant', constant_values=-1000)\n",
        "    return patch\n"
      ],
      "metadata": {
        "id": "cGrm-f_gs0XK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------------------------------\n",
        "# Dataset\n",
        "# -------------------------------------------------\n",
        "class LunaDataset(Dataset):\n",
        "    def _init_(self, candidates_file, ct_dir, transform=None):\n",
        "        self.df = pd.read_csv(candidates_file)\n",
        "        self.ct_dir = ct_dir\n",
        "        self.transform = transform\n",
        "        self.cache = {}\n",
        "\n",
        "    def _len_(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def _getitem_(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        seriesuid = row['seriesuid']\n",
        "        world_coord = np.array([row['coordZ'], row['coordY'], row['coordX']])\n",
        "        label = row['class']\n",
        "\n",
        "        if seriesuid not in self.cache:\n",
        "            img, origin, spacing = load_itk(os.path.join(self.ct_dir, seriesuid + '.mhd'))\n",
        "            self.cache[seriesuid] = (img, origin, spacing)\n",
        "        else:\n",
        "            img, origin, spacing = self.cache[seriesuid]\n",
        "\n",
        "        voxel_coord = world_to_voxel(world_coord, origin, spacing)\n",
        "        patch = extract_patch(img, voxel_coord, PATCH_SIZE)\n",
        "        patch = np.clip(patch, -1000, 400)\n",
        "        patch = (patch + 1000) / 1400\n",
        "\n",
        "        patch = torch.tensor(patch, dtype=torch.float32).unsqueeze(0)\n",
        "        label = torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "        return patch, label\n",
        "\n"
      ],
      "metadata": {
        "id": "q42b5OFss_O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# Model\n",
        "# -------------------------------------------------\n",
        "class SimpleViT3D(nn.Module):\n",
        "    def _init_(self):\n",
        "        super(SimpleViT3D, self)._init_()\n",
        "        self.conv1 = nn.Conv3d(1, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, stride=2, padding=1)\n",
        "        self.transformer_layer = nn.TransformerEncoderLayer(d_model=32, nhead=4, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(self.transformer_layer, num_layers=2)\n",
        "        self.fc = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        b, c, d, h, w = x.shape\n",
        "        x = x.view(b, c, -1).transpose(1, 2)\n",
        "        x = self.transformer(x)\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x.squeeze(1)\n",
        "\n"
      ],
      "metadata": {
        "id": "rfQYIi36tIbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# Training and Evaluation\n",
        "# -------------------------------------------------\n",
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for inputs, labels in tqdm(loader):\n",
        "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / len(loader)\n",
        "\n",
        "def eval_epoch(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    preds = []\n",
        "    truths = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(loader):\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            preds.append(torch.sigmoid(outputs).cpu().numpy())\n",
        "            truths.append(labels.cpu().numpy())\n",
        "            preds_binary = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            correct += (preds_binary == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    accuracy = correct / total\n",
        "    return running_loss / len(loader), accuracy, np.concatenate(preds), np.concatenate(truths)\n"
      ],
      "metadata": {
        "id": "kZc_u9GUtML4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------------------------------\n",
        "# Main\n",
        "# -------------------------------------------------\n",
        "train_dataset = LunaDataset(CANDIDATES_CSV, CT_SCANS_DIR)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "model = SimpleViT3D().to(DEVICE)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "train_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_acc, _, _ = eval_epoch(model, train_loader, criterion)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Loss {train_loss:.4f} | Val Acc {val_acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "nEwa2V8WtPCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# Plotting\n",
        "# -------------------------------------------------\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IXm_Vv3HtQrq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}